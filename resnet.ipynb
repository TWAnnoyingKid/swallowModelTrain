{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 導入必要的庫\n",
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "import noisereduce as nr\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from collections import Counter, defaultdict\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, BatchNormalization, Dropout, Flatten, Dense, GlobalAveragePooling2D, Add, Activation\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(\"TensorFlow 版本:\", tf.__version__)\n",
    "print(\"GPU 可用:\", tf.config.list_physical_devices('GPU'))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定義資料目錄\n",
    "data_dir = 'data/'  # 替換為您的數據目錄\n",
    "\n",
    "# 定義類別和對應的標籤\n",
    "categories = {'non': 0, 'swallow': 1}\n",
    "\n",
    "# 列出所有音頻文件及其標籤\n",
    "audio_files = []\n",
    "labels = []\n",
    "\n",
    "for category, label in categories.items():\n",
    "    category_dir = os.path.join(data_dir, category)\n",
    "    if not os.path.exists(category_dir):\n",
    "        print(f\"目錄 {category_dir} 不存在。請確認路徑正確。\")\n",
    "        continue\n",
    "    for file in os.listdir(category_dir):\n",
    "        if file.endswith('.wav'):\n",
    "            file_path = os.path.join(category_dir, file)\n",
    "            audio_files.append(file_path)\n",
    "            labels.append(label)\n",
    "\n",
    "print(f\"總音頻文件數量: {len(audio_files)}\")\n",
    "print(f\"標籤分佈: {Counter(labels)} (非吞嚥: {categories['non']}, 吞嚥: {categories['swallow']})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定義音頻處理函數\n",
    "def load_audio(file_path, sr=22050):\n",
    "    y, sr = librosa.load(file_path, sr=sr)\n",
    "    return y, sr\n",
    "\n",
    "def reduce_noise_signal(y, sr):\n",
    "    if len(y) < int(0.5 * sr):\n",
    "        noise_sample = y\n",
    "    else:\n",
    "        noise_sample = y[:int(0.5 * sr)]\n",
    "    y_reduced = nr.reduce_noise(y=y, sr=sr, y_noise=noise_sample)\n",
    "    return y_reduced\n",
    "\n",
    "def split_audio(y, sr, segment_length=1.0, hop_length=0.5):\n",
    "    segment_samples = int(segment_length * sr)\n",
    "    hop_samples = int(hop_length * sr)\n",
    "    segments = []\n",
    "    num_segments = 0\n",
    "\n",
    "    for start in range(0, len(y) - segment_samples + 1, hop_samples):\n",
    "        end = start + segment_samples\n",
    "        segments.append(y[start:end])\n",
    "        num_segments += 1\n",
    "\n",
    "    # 處理最後一個不足長度的片段\n",
    "    remaining_samples = len(y) - (num_segments * hop_samples)\n",
    "    if remaining_samples > 0 and remaining_samples < segment_samples:\n",
    "        last_segment = y[-segment_samples:]\n",
    "        padding = segment_samples - len(last_segment)\n",
    "        last_segment_padded = np.pad(last_segment, (0, padding), mode='constant')\n",
    "        segments.append(last_segment_padded)\n",
    "\n",
    "    return segments\n",
    "\n",
    "def extract_features(y, sr, n_mels=128, n_fft=2048, hop_length=512, fixed_length=130):\n",
    "    mel_spec = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=n_mels,\n",
    "                                              n_fft=n_fft, hop_length=hop_length)\n",
    "    mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "\n",
    "    # 固定長度\n",
    "    mel_spec_db = librosa.util.fix_length(mel_spec_db, size=fixed_length, axis=1)\n",
    "\n",
    "    return mel_spec_db\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化特徵和標籤列表\n",
    "features = []\n",
    "labels_processed = []\n",
    "\n",
    "# 計數每個類別的片段數量\n",
    "segment_counts = defaultdict(int)\n",
    "\n",
    "# 定義固定的時間步數\n",
    "fixed_length = 130\n",
    "\n",
    "# 迭代處理每個音頻文件\n",
    "for file_path, label in zip(audio_files, labels):\n",
    "    # 讀取音頻\n",
    "    y, sr = load_audio(file_path)\n",
    "\n",
    "    # 去噪（可選）\n",
    "    y = reduce_noise_signal(y, sr)\n",
    "\n",
    "    # 分割音頻\n",
    "    segments = split_audio(y, sr, segment_length=1.0, hop_length=0.5)\n",
    "\n",
    "    # 如果分割後沒有片段，跳過該文件\n",
    "    if not segments:\n",
    "        continue\n",
    "\n",
    "    # 對每個片段提取特徵\n",
    "    for segment in segments:\n",
    "        mel_spec = extract_features(segment, sr, fixed_length=fixed_length)\n",
    "        mel_spec = mel_spec[..., np.newaxis]  # 添加channel維度 (128, 130, 1)\n",
    "        features.append(mel_spec)\n",
    "        labels_processed.append(label)\n",
    "        segment_counts[label] += 1\n",
    "\n",
    "print(f\"總片段數量: {len(features)}\")\n",
    "print(\"每個類別的片段數量:\", dict(segment_counts))\n",
    "# 檢查所有特徵的形狀是否一致\n",
    "for i, feature in enumerate(features):\n",
    "    if feature.shape != (128, fixed_length, 1):\n",
    "        print(f\"片段 {i} 的形狀不一致: {feature.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 將特徵和標籤轉換為NumPy數組\n",
    "X = np.array(features)\n",
    "y = np.array(labels_processed)\n",
    "print(f\"特徵形狀: {X.shape}\")  # 應為 (samples, 128, 130, 1)\n",
    "print(f\"標籤形狀: {y.shape}\")\n",
    "\n",
    "# 將數值標準化到0-1之間\n",
    "X = X / np.max(X)\n",
    "print(f\"標準化後的特徵形狀: {X.shape}\")\n",
    "\n",
    "# 調整數據形狀為 (samples, height, width, channels)\n",
    "# 這裡將保持高度=128, 寬度=130, channels=1\n",
    "# ResNet 在 Keras 中需要 (height, width, channels)\n",
    "print(\"原始X形狀:\", X.shape)\n",
    "\n",
    "# 分割訓練集和測試集\n",
    "try:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "    print(f\"訓練集大小: {X_train.shape}\")\n",
    "    print(f\"測試集大小: {X_test.shape}\")\n",
    "except ValueError as e:\n",
    "    print(\"分層抽樣失敗，嘗試不使用 stratify\")\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    print(f\"訓練集大小: {X_train.shape}\")\n",
    "    print(f\"測試集大小: {X_test.shape}\")\n",
    "\n",
    "# 將標籤轉為類別\n",
    "y_train = to_categorical(y_train, num_classes=2)\n",
    "y_test = to_categorical(y_test, num_classes=2)\n",
    "print(f\"訓練集標籤形狀: {y_train.shape}\")\n",
    "print(f\"測試集標籤形狀: {y_test.shape}\")\n",
    "\n",
    "# 確保 y_train_labels 是一維的\n",
    "y_train_labels = np.argmax(y_train, axis=1).astype(int).flatten()\n",
    "\n",
    "print(\"y_train_labels shape:\", y_train_labels.shape)  # 應為 (n_samples,)\n",
    "print(\"y_train_labels:\", y_train_labels[:10])  # 應為 [0, 1, 0, 0, ...]\n",
    "\n",
    "# 獲取唯一類別\n",
    "classes = np.unique(y_train_labels)\n",
    "print(\"唯一類別:\", classes)\n",
    "\n",
    "# 計算類別權重\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=classes, y=y_train_labels)\n",
    "class_weights_dict = {i: weight for i, weight in zip(classes, class_weights)}\n",
    "print(\"類別權重:\", class_weights_dict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, Activation, Add, GlobalAveragePooling2D, Dense, Dropout, MaxPooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def residual_block(x, filters, kernel_size=3, stride=1, conv_shortcut=True, name=None):\n",
    "    \"\"\"A residual block.\n",
    "    \n",
    "    Arguments:\n",
    "        x: input tensor.\n",
    "        filters: integer, filters of the bottleneck layer.\n",
    "        kernel_size: default 3, the kernel size of middle conv layer at main path.\n",
    "        stride: default 1, stride of the first layer in the block.\n",
    "        conv_shortcut: default True, whether to use a convolutional layer to match dimensions.\n",
    "        name: string, block label.\n",
    "    \n",
    "    Returns:\n",
    "        Output tensor for the block.\n",
    "    \"\"\"\n",
    "    bn_axis = 3  # Channels last\n",
    "\n",
    "    shortcut = x\n",
    "    if conv_shortcut:\n",
    "        # 修改這裡，將 filters 改為 4 * filters\n",
    "        shortcut = Conv2D(4 * filters, 1, strides=stride, name=name + '_0_conv')(x)\n",
    "        shortcut = BatchNormalization(axis=bn_axis, epsilon=1.001e-5, name=name + '_0_bn')(shortcut)\n",
    "    \n",
    "    # 主路徑\n",
    "    x = Conv2D(filters, 1, strides=stride, name=name + '_1_conv')(x)\n",
    "    x = BatchNormalization(axis=bn_axis, epsilon=1.001e-5, name=name + '_1_bn')(x)\n",
    "    x = Activation('relu', name=name + '_1_relu')(x)\n",
    "    \n",
    "    x = Conv2D(filters, kernel_size, padding='same', name=name + '_2_conv')(x)\n",
    "    x = BatchNormalization(axis=bn_axis, epsilon=1.001e-5, name=name + '_2_bn')(x)\n",
    "    x = Activation('relu', name=name + '_2_relu')(x)\n",
    "    \n",
    "    x = Conv2D(4 * filters, 1, name=name + '_3_conv')(x)\n",
    "    x = BatchNormalization(axis=bn_axis, epsilon=1.001e-5, name=name + '_3_bn')(x)\n",
    "    \n",
    "    # 調試信息：打印主路徑和捷徑路徑的形狀\n",
    "    print(f\"{name}_shortcut shape: {shortcut.shape}\")\n",
    "    print(f\"{name}_main path shape: {x.shape}\")\n",
    "    \n",
    "    x = Add(name=name + '_add')([shortcut, x])\n",
    "    x = Activation('relu', name=name + '_out')(x)\n",
    "    return x\n",
    "\n",
    "def build_resnet(input_shape, num_classes=2, depth=50):\n",
    "    \"\"\"Builds a ResNet model.\n",
    "    \n",
    "    Arguments:\n",
    "        input_shape: tuple, the shape of input data, e.g., (128, 130, 1)\n",
    "        num_classes: integer, number of classes for classification.\n",
    "        depth: integer, depth of the ResNet model.\n",
    "    \n",
    "    Returns:\n",
    "        Keras Model instance.\n",
    "    \"\"\"\n",
    "    if depth == 50:\n",
    "        layers_config = [3, 4, 6, 3]\n",
    "    elif depth == 101:\n",
    "        layers_config = [3, 4, 23, 3]\n",
    "    elif depth == 152:\n",
    "        layers_config = [3, 8, 36, 3]\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported ResNet depth: {}. Use 50, 101, or 152.\".format(depth))\n",
    "    \n",
    "    bn_axis = 3  # Channels last\n",
    "\n",
    "    inputs = Input(shape=input_shape, name='input')\n",
    "\n",
    "    # Initial convolution and max-pooling\n",
    "    x = Conv2D(64, 7, strides=1, padding='same', name='conv1_conv')(inputs)  # stride 改為 1\n",
    "    x = BatchNormalization(axis=bn_axis, epsilon=1.001e-5, name='conv1_bn')(x)\n",
    "    x = Activation('relu', name='conv1_relu')(x)\n",
    "    x = MaxPooling2D(3, strides=2, padding='same', name='pool1_pool')(x)\n",
    "\n",
    "    # Residual blocks\n",
    "    filters = 64\n",
    "    for stage, blocks in enumerate(layers_config):\n",
    "        for block in range(blocks):\n",
    "            if block == 0:\n",
    "                if stage != 0:\n",
    "                    stride = 2\n",
    "                else:\n",
    "                    stride = 1\n",
    "                conv_shortcut = True\n",
    "            else:\n",
    "                stride = 1\n",
    "                conv_shortcut = False\n",
    "            x = residual_block(\n",
    "                x, \n",
    "                filters, \n",
    "                stride=stride, \n",
    "                conv_shortcut=conv_shortcut, \n",
    "                name='conv{}_block{}'.format(stage + 2, block + 1)\n",
    "            )\n",
    "        filters *= 2\n",
    "\n",
    "    # Global Average Pooling and output\n",
    "    x = GlobalAveragePooling2D(name='avg_pool')(x)\n",
    "    x = Dense(num_classes, activation='softmax', name='fc')(x)\n",
    "\n",
    "    model = Model(inputs, x, name='resnet{}'.format(depth))\n",
    "    return model\n",
    "\n",
    "# 獲取輸入形狀\n",
    "input_shape = X_train.shape[1:]  # 假設形狀為 (128, 130, 1)\n",
    "print(\"輸入形狀:\", input_shape)\n",
    "\n",
    "# 建立 ResNet50 模型\n",
    "model = build_resnet(input_shape=input_shape, num_classes=2, depth=50)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 訓練模型，並使用類別權重和早停法\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=30, batch_size=16,\n",
    "                    validation_data=(X_test, y_test),\n",
    "                    class_weight=class_weights_dict)\n",
    "\n",
    "# 繪製訓練過程\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "# 繪製損失\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], label='Train_Loss')\n",
    "plt.plot(history.history['val_loss'], label='Val_Loss')\n",
    "plt.title('Loss_Curve')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.ylim(0, 1)\n",
    "plt.legend()\n",
    "\n",
    "# 繪製準確率\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['accuracy'], label='Train_Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Val_Accuracy')\n",
    "plt.title('Accuracy_Curve')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim(0, 1)\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 評估模型在測試集上的表現\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"測試集損失: {loss:.4f}\")\n",
    "print(f\"測試集準確率: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 預測測試集\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "# 混淆矩陣\n",
    "cm = confusion_matrix(y_true, y_pred_classes)\n",
    "print(\"混淆矩陣:\")\n",
    "print(cm)\n",
    "\n",
    "# 分類報告\n",
    "print(\"\\n分類報告:\")\n",
    "print(classification_report(y_true, y_pred_classes, target_names=['NON', 'Swallow']))\n",
    "\n",
    "# 可視化混淆矩陣\n",
    "plt.figure(figsize=(6,5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['NON', 'Swallow'],\n",
    "            yticklabels=['NON', 'Swallow'])\n",
    "plt.ylabel('GroundTruth')\n",
    "plt.xlabel('Predict')\n",
    "plt.title('Confusion_Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定義滑動窗口預測函數\n",
    "def sliding_window_predict(y, sr, model, window_length=1.0, hop_length=0.5, threshold=0.5, fixed_length=130):\n",
    "    \"\"\"\n",
    "    使用滑動窗口方法對整個音頻進行預測，並計數吞嚥聲音的數量。\n",
    "\n",
    "    參數:\n",
    "    - y: 音頻信號\n",
    "    - sr: 採樣率\n",
    "    - model: 已訓練的ResNet模型\n",
    "    - window_length: 窗口長度（秒）\n",
    "    - hop_length: 窗口跳步長度（秒）\n",
    "    - threshold: 判斷為吞嚥聲音的概率閾值\n",
    "    - fixed_length: 固定的時間步數（帧數）\n",
    "\n",
    "    返回:\n",
    "    - count: 吞嚥聲音的數量\n",
    "    \"\"\"\n",
    "    window_samples = int(window_length * sr)\n",
    "    hop_samples = int(hop_length * sr)\n",
    "    predictions = []\n",
    "\n",
    "    for start in range(0, len(y) - window_samples + 1, hop_samples):\n",
    "        end = start + window_samples\n",
    "        window = y[start:end]\n",
    "        mel_spec = extract_features(window, sr, fixed_length=fixed_length)\n",
    "        mel_spec = mel_spec[..., np.newaxis]  # (128, 130, 1)\n",
    "\n",
    "        # 處理可能的NaN或極小值\n",
    "        if np.max(mel_spec) == 0:\n",
    "            mel_spec = mel_spec + 1e-6\n",
    "        mel_spec = mel_spec / np.max(mel_spec)  # 標準化\n",
    "\n",
    "        # 調整形狀為 (samples, height, width, channels)\n",
    "        mel_spec = mel_spec.reshape(1, 128, fixed_length, 1)  # (1, 128, 130, 1)\n",
    "\n",
    "        pred = model.predict(mel_spec, verbose=0)\n",
    "        predictions.append(pred[0][1])  # 吞嚥聲音的概率\n",
    "\n",
    "    # 根據閾值判斷吞嚥事件\n",
    "    swallowing_events = [i for i, prob in enumerate(predictions) if prob > threshold]\n",
    "\n",
    "    # 去除重疊的事件\n",
    "    min_distance = int(window_length / hop_length * 1)  # 最小間隔，根據實際情況調整\n",
    "    final_events = []\n",
    "    last_event = -min_distance\n",
    "    for event in swallowing_events:\n",
    "        if event - last_event > min_distance:\n",
    "            final_events.append(event)\n",
    "            last_event = event\n",
    "\n",
    "    return len(final_events)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定義新的音頻文件路徑\n",
    "new_audio_path = '音檔\\比較輕吞.wav'  # 替換為您的音頻文件路徑\n",
    "\n",
    "# 檢查文件是否存在並進行預測\n",
    "if not os.path.exists(new_audio_path):\n",
    "    print(f\"音頻文件 {new_audio_path} 不存在。請確認路徑正確。\")\n",
    "else:\n",
    "    # 讀取新的音頻文件\n",
    "    y_new, sr_new = load_audio(new_audio_path)\n",
    "\n",
    "    # 可選：去噪\n",
    "    y_new = reduce_noise_signal(y_new, sr_new)\n",
    "\n",
    "    # 使用滑動窗口方法進行預測和計數\n",
    "    count = sliding_window_predict(y_new, sr_new, model, window_length=1.0, hop_length=0.5, threshold=0.5, fixed_length=130)\n",
    "    print(f\"吞嚥聲音數量: {count}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "swallow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
