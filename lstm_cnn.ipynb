{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "def extract_mel_spectrogram(file_path, n_mels=128, hop_length=64, fixed_length=160, sr=22050, duration=0.5):\n",
    "    \"\"\"\n",
    "    從音訊文件中提取梅爾頻譜圖。\n",
    "    \n",
    "    參數:\n",
    "    - file_path (str): 音訊文件路徑\n",
    "    - n_mels (int): 梅爾頻帶數量\n",
    "    - hop_length (int): 每次窗口移動的樣本數\n",
    "    - fixed_length (int): 固定的時間步數（橫向維度）\n",
    "    - sr (int): 採樣率\n",
    "    - duration (float): 音訊片段時長（秒）\n",
    "    \n",
    "    返回:\n",
    "    - mel_spec_db (np.ndarray): 處理後的梅爾頻譜圖\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # 加載音訊文件\n",
    "        y, sr = librosa.load(file_path, sr=sr, duration=duration)\n",
    "        \n",
    "        # 確保音訊長度固定，pad 或 truncate\n",
    "        y = librosa.util.fix_length(y, size=int(sr * duration))\n",
    "        \n",
    "        # 提取梅爾頻譜圖\n",
    "        mel_spec = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=n_mels, hop_length=hop_length)\n",
    "        mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "        \n",
    "        # 填充或截斷時間步數\n",
    "        if mel_spec_db.shape[1] < fixed_length:\n",
    "            pad_width = fixed_length - mel_spec_db.shape[1]\n",
    "            mel_spec_db = np.pad(mel_spec_db, pad_width=((0,0), (0, pad_width)), mode='constant')\n",
    "        else:\n",
    "            mel_spec_db = mel_spec_db[:, :fixed_length]\n",
    "        \n",
    "        # 重塑或插值至 (固定高度 x 固定寬度)\n",
    "        mel_image = Image.fromarray(mel_spec_db)\n",
    "        mel_image = mel_image.resize((128, fixed_length))  # (width, height)\n",
    "        mel_spec_db = np.array(mel_image)\n",
    "        \n",
    "        return mel_spec_db.astype(np.float32)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"處理文件 {file_path} 時出現錯誤: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(swallow_dir, non_dir, n_mels=128, hop_length=64, fixed_length=160, sr=22050, duration=0.5):\n",
    "    \"\"\"\n",
    "    建立資料集。\n",
    "    \n",
    "    參數:\n",
    "    - swallow_dir (str): 吞嚥聲音檔案資料夾路徑\n",
    "    - non_dir (str): 非吞嚥聲音檔案資料夾路徑\n",
    "    - 其他參數同上\n",
    "    \n",
    "    返回:\n",
    "    - data (np.ndarray): 梅爾頻譜圖數據\n",
    "    - labels (np.ndarray): 標籤數據\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    labels = []\n",
    "    \n",
    "    # 加載吞嚥聲音檔案\n",
    "    for file in os.listdir(swallow_dir):\n",
    "        if file.endswith('.wav'):\n",
    "            file_path = os.path.join(swallow_dir, file)\n",
    "            mel = extract_mel_spectrogram(file_path, n_mels=n_mels, hop_length=hop_length, \n",
    "                                         fixed_length=fixed_length, sr=sr, duration=duration)\n",
    "            if mel is not None:\n",
    "                data.append(mel)\n",
    "                labels.append(1)\n",
    "    \n",
    "    # 加載非吞嚥聲音檔案\n",
    "    for file in os.listdir(non_dir):\n",
    "        if file.endswith('.wav'):\n",
    "            file_path = os.path.join(non_dir, file)\n",
    "            mel = extract_mel_spectrogram(file_path, n_mels=n_mels, hop_length=hop_length, \n",
    "                                         fixed_length=fixed_length, sr=sr, duration=duration)\n",
    "            if mel is not None:\n",
    "                data.append(mel)\n",
    "                labels.append(0)\n",
    "    \n",
    "    return np.array(data), np.array(labels)\n",
    "\n",
    "def add_background_noise(y, noise_factor=0.005):\n",
    "    \"\"\"\n",
    "    向音訊添加背景噪音。\n",
    "    \n",
    "    參數:\n",
    "    - y (np.ndarray): 音訊數據\n",
    "    - noise_factor (float): 噪音強度因子\n",
    "    \n",
    "    返回:\n",
    "    - y_noisy (np.ndarray): 添加噪音後的音訊數據\n",
    "    \"\"\"\n",
    "    noise = np.random.randn(len(y))\n",
    "    y_noisy = y + noise_factor * noise\n",
    "    y_noisy = y_noisy.astype(type(y[0]))\n",
    "    return y_noisy\n",
    "\n",
    "def adjust_volume(y, factor=0.8):\n",
    "    \"\"\"\n",
    "    調整音訊的音量。\n",
    "    \n",
    "    參數:\n",
    "    - y (np.ndarray): 音訊數據\n",
    "    - factor (float): 音量調整因子\n",
    "    \n",
    "    返回:\n",
    "    - y_adjusted (np.ndarray): 調整音量後的音訊數據\n",
    "    \"\"\"\n",
    "    return y * factor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 定義資料夾路徑\n",
    "swallow_dir = 'sound_split_data/swallow'  # 替換為實際路徑\n",
    "non_dir = 'sound_split_data/non'          # 替換為實際路徑\n",
    "\n",
    "# 建立資料集\n",
    "X, y = create_dataset(swallow_dir, non_dir, sr=22050)\n",
    "print(f\"資料集大小: {X.shape}, 標籤大小: {y.shape}\")  # 應為 (num_samples, 160, 128)\n",
    "\n",
    "# 移除可能的空值樣本\n",
    "valid_indices = [i for i in range(len(X)) if X[i] is not None]\n",
    "X = X[valid_indices]\n",
    "y = y[valid_indices]\n",
    "\n",
    "# 標準化\n",
    "scaler = StandardScaler()\n",
    "X_reshaped = X.reshape(X.shape[0], -1)  # 將每個頻譜圖展平成一維 (num_samples, 160*128=20480)\n",
    "X_scaled = scaler.fit_transform(X_reshaped)  # (num_samples, 20480)\n",
    "\n",
    "# 重塑為 (num_samples, 160, 128, 1)\n",
    "X_scaled = X_scaled.reshape(X.shape[0], 160, 128, 1)\n",
    "\n",
    "# 複製通道以符合模型要求 (num_samples, 160, 128, 3)\n",
    "X_scaled = np.repeat(X_scaled, 3, axis=-1)  # 現在形狀為 (num_samples, 160, 128, 3)\n",
    "\n",
    "# 確認數據形狀\n",
    "print(f\"重塑後資料集大小: {X_scaled.shape}, 標籤大小: {y.shape}\")  # (num_samples, 160, 128, 3), (num_samples,)\n",
    "\n",
    "# 拆分訓練集和驗證集\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_scaled, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "print(f\"訓練集大小: {X_train.shape}, 驗證集大小: {X_val.shape}\")  # (num_train, 160, 128, 3), (num_val,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "\n",
    "def build_simple_cnn_lstm(input_shape):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    \n",
    "    # 簡單的 CNN 模塊\n",
    "    x = layers.Conv2D(32, (3,3), activation='relu', padding='same')(inputs)\n",
    "    x = layers.MaxPooling2D((2,2))(x)  # (80, 64, 32)\n",
    "    x = layers.Dropout(0.25)(x)\n",
    "    \n",
    "    x = layers.Conv2D(64, (3,3), activation='relu', padding='same')(x)\n",
    "    x = layers.MaxPooling2D((2,2))(x)  # (40, 32, 64)\n",
    "    x = layers.Dropout(0.25)(x)\n",
    "    \n",
    "    x = layers.Conv2D(128, (3,3), activation='relu', padding='same')(x)\n",
    "    x = layers.MaxPooling2D((2,2))(x)  # (20, 16, 128)\n",
    "    x = layers.Dropout(0.25)(x)\n",
    "    # Flatten 和 Dense\n",
    "    x = layers.Flatten()(x)  # (20*16*128, )\n",
    "    x = layers.Dense(128, activation='relu')(x)\n",
    "    x = layers.Dropout(0.25)(x)\n",
    "    \n",
    "    # 為 LSTM 準備序列格式\n",
    "    x = layers.Reshape((1, 128))(x)  # (1, 256)\n",
    "    x = layers.LSTM(64, return_sequences=False, recurrent_dropout=0.2)(x)\n",
    "    \n",
    "    # 輸出層\n",
    "    outputs = layers.Dense(1, activation='sigmoid')(x)\n",
    "    \n",
    "    model = models.Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "input_shape = (160, 128, 3)  # (fixed_length, n_mels, channels)\n",
    "model = build_simple_cnn_lstm(input_shape)\n",
    "\n",
    "# 編譯模型\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "# 訓練模型\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=5,\n",
    "    batch_size=64,\n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 繪製訓練與驗證的準確率\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Train_accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Val_accuracy')\n",
    "plt.legend()\n",
    "plt.title('accuracy')\n",
    "\n",
    "# 繪製訓練與驗證的損失\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Train_loss')\n",
    "plt.plot(history.history['val_loss'], label='Val_loss')\n",
    "plt.legend()\n",
    "plt.title('loss')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m roc_curve, auc\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# 在驗證集上進行預測\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m y_pred_prob \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mpredict(X_val)\n\u001b[0;32m      6\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m (y_pred_prob \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.5\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# 混淆矩陣\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# 在驗證集上進行預測\n",
    "y_pred_prob = model.predict(X_val)\n",
    "y_pred = (y_pred_prob > 0.5).astype(int)\n",
    "# 混淆矩陣\n",
    "cm = confusion_matrix(y_val, y_pred)\n",
    "print(\"混淆矩陣:\")\n",
    "print(cm)\n",
    "# 分類報告\n",
    "cr = classification_report(y_val, y_pred, target_names=['Non-Swallow', 'Swallow'])\n",
    "print(\"分類報告:\")\n",
    "print(cr)\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_val, y_pred_prob)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('FP')\n",
    "plt.ylabel('TP')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_swallowing(file_path, model, scaler, n_mels=128, hop_length=64, fixed_length=160, sr=22050):\n",
    "    \"\"\"\n",
    "    計算單一音訊文件中的吞嚥聲數量。\n",
    "    \n",
    "    參數:\n",
    "    - file_path (str): 音訊文件路徑\n",
    "    - model (tf.keras.Model): 訓練好的模型\n",
    "    - scaler (StandardScaler): 訓練階段使用的標準化器\n",
    "    - n_mels (int): 梅爾頻帶數量\n",
    "    - hop_length (int): 每次窗口移動的樣本數\n",
    "    - fixed_length (int): 固定的時間步數（橫向維度）\n",
    "    - sr (int): 採樣率\n",
    "    \n",
    "    返回:\n",
    "    - count (int): 檢測到的吞嚥聲數量\n",
    "    \"\"\"\n",
    "    y, sr = librosa.load(file_path, duration=30, sr=sr)\n",
    "    chunk_length = int(sr * 0.5)  # 0.5秒\n",
    "    count = 0\n",
    "    for i in range(0, len(y), chunk_length):\n",
    "        chunk = y[i:i+chunk_length]\n",
    "        if len(chunk) < chunk_length:\n",
    "            # 填充\n",
    "            chunk = librosa.util.fix_length(chunk, size=chunk_length)\n",
    "        mel_spec = librosa.feature.melspectrogram(y=chunk, sr=sr, n_mels=n_mels, hop_length=hop_length)\n",
    "        mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "        # 填充或截斷\n",
    "        if mel_spec_db.shape[1] < fixed_length:\n",
    "            pad_width = fixed_length - mel_spec_db.shape[1]\n",
    "            mel_spec_db = np.pad(mel_spec_db, pad_width=((0,0), (0, pad_width)), mode='constant')\n",
    "        else:\n",
    "            mel_spec_db = mel_spec_db[:, :fixed_length]\n",
    "        # 重塑或插值至160x128\n",
    "        mel_image = Image.fromarray(mel_spec_db)\n",
    "        mel_image = mel_image.resize((128, fixed_length))  # (width, height)\n",
    "        mel_spec_db = np.array(mel_image)\n",
    "        # 標準化\n",
    "        X_scaled = scaler.transform(mel_spec_db.reshape(1, -1)).reshape(mel_spec_db.shape)\n",
    "        # 調整形狀\n",
    "        X_scaled = X_scaled.reshape(1, fixed_length, n_mels, 1)\n",
    "        # 複製通道以符合模型要求\n",
    "        X_scaled = np.repeat(X_scaled, 3, axis=-1)  # 現在形狀為 (1, 160, 128, 3)\n",
    "        # 預測\n",
    "        prediction = model.predict(X_scaled)\n",
    "        if prediction > 0.5:\n",
    "            print(f\"swallow conf:{prediction}\")\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "# 範例用法\n",
    "file_path = '音檔\\測試RSST.wav'  # 替換為實際路徑\n",
    "num_swallow = count_swallowing(file_path, model, scaler)\n",
    "print(f\"吞嚥聲數量: {num_swallow}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "swallow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
